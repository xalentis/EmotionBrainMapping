# Decoding Neural Emotion Patterns through Large Language Model Embeddings

Gideon Vos, Liza van Eijk, Zoltan Sarnyai, Mostafa Rahimi Azghadi

Linking emotional expression in natural language to brain function remains a central challenge in neuroscience and affective computing. While neuroimaging offers insight into emotion localization, it is costly and limited to controlled settings. In this study, we introduce a computational framework that maps textual emotional content to neuroanatomical brain regions, enabling scalable, imaging-free emotionâ€“brain research. Our proposed method combines semantic embeddings, dimensionality reduction, and clustering to identify emotional states, which are mapped onto brain regions associated with affective processing. We applied this framework across three experiments: i) comparing conversational data from healthy and depressed individuals, ii) analyzing a large-scale emotion dataset, and iii) contrasting human language with outputs from a large language model. Emotional intensity was quantified using a lexical scoring system sensitive to keywords, syntax, and modifiers. This approach produced neuro-anatomically plausible mappings with high spatial specificity. Depressed subjects exhibited reduced engagement of the left insula and raphe nuclei, regions linked to interoceptive awareness and serotonergic function. The framework reliably differentiated discrete emotions and revealed that LLM-generated texts, while capturing basic affective patterns, lacked the nuanced activation seen in human language, particularly in empathy and self-referential regions such as the medial prefrontal and posterior cingulate cortices. This work establishes a scalable, cost-effective alternative to neuroimaging, advancing both clinical and computational models of emotion, while providing a neuro-inspired benchmark for assessing how closely AI-generated language mirrors human emotional expression.
